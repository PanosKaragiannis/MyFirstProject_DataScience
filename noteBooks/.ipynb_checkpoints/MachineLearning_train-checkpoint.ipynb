{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1598,
     "status": "ok",
     "timestamp": 1591269833414,
     "user": {
      "displayName": "Ioanna Kountouri",
      "photoUrl": "",
      "userId": "18315338504972529308"
     },
     "user_tz": -180
    },
    "id": "nhnYb1lHtZBi",
    "outputId": "6b2f0a51-d70b-4c82-ed52-4f7638083f33"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler # Normalization - Standardization\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 648,
     "status": "ok",
     "timestamp": 1591269860991,
     "user": {
      "displayName": "Ioanna Kountouri",
      "photoUrl": "",
      "userId": "18315338504972529308"
     },
     "user_tz": -180
    },
    "id": "Va2SSOfothS6",
    "outputId": "d787ab35-aed1-40fe-b8d0-8f6340994653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15544 entries, 0 to 15543\n",
      "Data columns (total 56 columns):\n",
      "Unnamed: 0                                  15544 non-null int64\n",
      "Australia                                   15544 non-null int64\n",
      "Central_Rich_Europe                         15544 non-null int64\n",
      "East_Europe_Balkans                         15544 non-null int64\n",
      "Mediteranian_Europe                         15544 non-null int64\n",
      "North_Europe_Scand                          15544 non-null int64\n",
      "user_id                                     15544 non-null object\n",
      "birth_year                                  15544 non-null int64\n",
      "country                                     15544 non-null object\n",
      "city                                        15544 non-null object\n",
      "created_date                                15544 non-null object\n",
      "user_settings_crypto_unlocked               15544 non-null int64\n",
      "plan                                        15544 non-null int64\n",
      "attributes_notifications_marketing_push     15544 non-null float64\n",
      "attributes_notifications_marketing_email    15544 non-null float64\n",
      "num_contacts                                15544 non-null int64\n",
      "num_referrals                               15544 non-null int64\n",
      "num_successful_referrals                    15544 non-null int64\n",
      "brand                                       15544 non-null int64\n",
      "age                                         15544 non-null int64\n",
      "total_amount                                15544 non-null float64\n",
      "number_transactions                         15544 non-null float64\n",
      "avg_amount                                  15544 non-null float64\n",
      "first_transaction                           15544 non-null object\n",
      "last_transaction                            15544 non-null object\n",
      "transaction_period                          15544 non-null float64\n",
      "user_active_time                            15544 non-null int64\n",
      "user_trans_time                             15544 non-null float64\n",
      "user_trans_periodicity                      15544 non-null float64\n",
      "ATM                                         15544 non-null float64\n",
      "CARD_PAYMENT                                15544 non-null float64\n",
      "CARD_REFUND                                 15544 non-null float64\n",
      "EXCHANGE                                    15544 non-null float64\n",
      "REFUND                                      15544 non-null float64\n",
      "TAX                                         15544 non-null float64\n",
      "TOPUP                                       15544 non-null float64\n",
      "TRANSFER                                    15544 non-null float64\n",
      "CHF                                         15544 non-null float64\n",
      "EUR                                         15544 non-null float64\n",
      "GBP                                         15544 non-null float64\n",
      "OTHER                                       15544 non-null float64\n",
      "BLACK_FRIDAY                                15544 non-null float64\n",
      "BLUE_TUESDAY                                15544 non-null float64\n",
      "ENGAGEMENT_SPLIT_BILL_RESTAURANT            15544 non-null float64\n",
      "INVEST_IN_GOLD                              15544 non-null float64\n",
      "JOINING_ANNIVERSARY                         15544 non-null float64\n",
      "LOST_CARD_ORDER                             15544 non-null float64\n",
      "MADE_MONEY_REQUEST_NOT_SPLIT_BILL           15544 non-null float64\n",
      "METAL_RESERVE_PLAN                          15544 non-null float64\n",
      "NO_INITIAL_CARD_ORDER                       15544 non-null float64\n",
      "NO_INITIAL_CARD_USE                         15544 non-null float64\n",
      "ONBOARDING_TIPS_ACTIVATED_USERS             15544 non-null float64\n",
      "PROMO                                       15544 non-null float64\n",
      "PROMO_CARD_ORDER                            15544 non-null float64\n",
      "REENGAGEMENT_ACTIVE_FUNDS                   15544 non-null float64\n",
      "WELCOME_BACK                                15544 non-null float64\n",
      "dtypes: float64(35), int64(15), object(6)\n",
      "memory usage: 6.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Define the path of the data set\n",
    "df = pd.read_csv('../processed_data/training_data.csv')\n",
    "test1 = pd.read_csv('../processed_data/testing_data.csv')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['user_settings_crypto_unlocked', 'num_contacts', 'brand', 'age', 'total_amount', 'number_transactions','avg_amount',\n",
    "            'transaction_period', 'user_active_time', 'user_trans_time', 'user_trans_periodicity','ATM', 'CARD_PAYMENT', 'CARD_REFUND', 'EXCHANGE', 'REFUND', 'TAX', 'TOPUP', \n",
    "            'TRANSFER',\n",
    "           'BLACK_FRIDAY', 'BLUE_TUESDAY', 'ENGAGEMENT_SPLIT_BILL_RESTAURANT', 'INVEST_IN_GOLD', 'JOINING_ANNIVERSARY',\n",
    "          'LOST_CARD_ORDER', 'MADE_MONEY_REQUEST_NOT_SPLIT_BILL', 'METAL_RESERVE_PLAN', 'NO_INITIAL_CARD_ORDER',\n",
    "          'NO_INITIAL_CARD_USE', 'ONBOARDING_TIPS_ACTIVATED_USERS', 'PROMO', 'PROMO_CARD_ORDER', 'REENGAGEMENT_ACTIVE_FUNDS',\n",
    "          'WELCOME_BACK',\n",
    "           'Australia', 'Central_Rich_Europe', 'East_Europe_Balkans', 'Mediteranian_Europe', 'North_Europe_Scand',\n",
    "           'CHF', 'EUR', 'GBP', 'OTHER']\n",
    "            \n",
    "types = ['ATM', 'CARD_PAYMENT', 'CARD_REFUND', 'EXCHANGE', 'REFUND', 'TAX', 'TOPUP', 'TRANSFER']\n",
    "status = ['BLACK_FRIDAY', 'BLUE_TUESDAY', 'ENGAGEMENT_SPLIT_BILL_RESTAURANT', 'INVEST_IN_GOLD', 'JOINING_ANNIVERSARY',\n",
    "          'LOST_CARD_ORDER', 'MADE_MONEY_REQUEST_NOT_SPLIT_BILL', 'METAL_RESERVE_PLAN', 'NO_INITIAL_CARD_ORDER',\n",
    "          'NO_INITIAL_CARD_USE', 'ONBOARDING_TIPS_ACTIVATED_USERS', 'PROMO', 'PROMO_CARD_ORDER', 'REENGAGEMENT_ACTIVE_FUNDS',\n",
    "          'WELCOME_BACK'] \n",
    "\n",
    "countries = ['Australia', 'Central_Rich_Europe', 'East_Europe_Balkans', 'Mediteranian_Europe', 'North_Europe_Scand']\n",
    "\n",
    "currency = ['CHF', 'EUR', 'GBP', 'OTHER']\n",
    "            \n",
    "class_y = ['plan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CtUKYt4QvRVF"
   },
   "outputs": [],
   "source": [
    "test = test1[features].copy()\n",
    "data = df[features].copy() # features\n",
    "y = df[class_y] # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VOQ42gis3Wxh"
   },
   "source": [
    "# Data splitting & Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7_kf0HKcztue"
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "x = data[features].copy() # features\n",
    "y = df[class_y].copy() # labels\n",
    "\n",
    "# x_train1 = x.copy()\n",
    "# y_train1 = y.copy()\n",
    "# x_test = test.copy()\n",
    "\n",
    "x_train1, x_test, y_train1, y_test = train_test_split(x, y, test_size=0.2)\n",
    "# print(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1499,
     "status": "ok",
     "timestamp": 1591269869418,
     "user": {
      "displayName": "Ioanna Kountouri",
      "photoUrl": "",
      "userId": "18315338504972529308"
     },
     "user_tz": -180
    },
    "id": "JUT3zdSY2l2P",
    "outputId": "57850e94-d7cc-4ca7-b9e6-7a5e3ca357c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11503\n",
      "932\n",
      "10571\n"
     ]
    }
   ],
   "source": [
    "# upsampling\n",
    "df1 = x_train1.copy()\n",
    "df1['plan'] = y_train1.copy()\n",
    "df1_minor = df1[df1.plan==1]\n",
    "df1_major = df1[df1.plan==0]\n",
    "\n",
    "smpl = len(df1_major) - len(df1_minor)\n",
    "print(len(df1_major))\n",
    "print(len(df1_minor))\n",
    "print(smpl)\n",
    "\n",
    "# X = data.drop('y', axis=1).values\n",
    "# y = data['y'].values\n",
    "\n",
    "# bool val to change between separated and non-separated upsampling\n",
    "case = True\n",
    "\n",
    "if case:\n",
    "    smote = SMOTE()\n",
    "    x_train, y_train = smote.fit_resample(x_train1, y_train1)\n",
    "\n",
    "#     x_train = pd.concat( [x_train, y_train], axis=1)\n",
    "#     x_train1 = pd.concat( [x_train1, y_train1], axis=1)\n",
    "else:\n",
    "    smoteenn = SMOTEENN()\n",
    "    # X_us_nn, y_us_nn = enn.fit_resample(x_train1, y_train1)\n",
    "    x_train, y_train = smoteenn.fit_resample(x_train1, y_train1)\n",
    "\n",
    "#     x_train = pd.concat( [x_train, y_train], axis=1)\n",
    "#     x_train1 = pd.concat( [x_train1, y_train1], axis=1)\n",
    "    \n",
    "# print('Dataset size before oversampling:', len(x_train1[x_train1.plan==1]), len(x_train1[x_train1.plan==0]))\n",
    "# print('Dataset size after oversampling: ', len(x_train[x_train.plan==1]), len(x_train[x_train.plan==0]))\n",
    "# x_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8K1Rjpa3Wxe"
   },
   "source": [
    "# Normalization - Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tcI77ZAzvYgn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52790095, -0.49051709,  1.11605699, ..., -0.4903752 ,\n",
       "        -0.37522331, -0.35361323],\n",
       "       [-0.52790095, -0.49051709,  1.11605699, ..., -0.47960344,\n",
       "        -0.33580603, -0.35361323],\n",
       "       [-0.52790095, -0.49051709, -0.89601159, ..., -0.47960344,\n",
       "        -0.37522331, -0.35361323],\n",
       "       ...,\n",
       "       [-0.52790095, -0.09939668, -0.89601159, ..., -0.50114696,\n",
       "        -0.22740852, -0.35361323],\n",
       "       [-0.52790095, -0.05338251,  1.11605699, ..., -0.50114696,\n",
       "         0.76787771,  1.3778752 ],\n",
       "       [-0.52790095, -0.42149584, -0.89601159, ..., -0.06489057,\n",
       "        -0.18306409, -0.35361323]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standardizing-normalizing the training-data in order to fit the models\n",
    "# thats the reason we use x_train\n",
    "S_scaler = StandardScaler() # MinMaxScaler()\n",
    "N_scaler = MinMaxScaler()\n",
    "N_features = features\n",
    "# S_scaler.fit(data[['num_contacts']])\n",
    "# data[['num_contacts']] = S_scaler.transform(data[['num_contacts']])\n",
    "\n",
    "S_scaler.fit_transform(x_train)\n",
    "S_scaler.transform(x_test)\n",
    "# data[N_features] = N_scaler.transform(data[N_features])\n",
    "# n_values = preprocessing.normalize(df[N_features])\n",
    "# data[N_features] = n_values\n",
    "# print(n_values)\n",
    "# data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FLrZOkws3Wxo"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1178,
     "status": "ok",
     "timestamp": 1591269880322,
     "user": {
      "displayName": "Ioanna Kountouri",
      "photoUrl": "",
      "userId": "18315338504972529308"
     },
     "user_tz": -180
    },
    "id": "KY5CJ0OOzXCe",
    "outputId": "ef71a231-c24a-4ffb-95ad-0b17ff29f8ea"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/linear_model/_logistic.py:1505: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.92698827 0.96587698 0.96326885 0.96196479 0.9654423 ]\n",
      "0.9585075587005468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98      2891\n",
      "           1       0.69      0.74      0.72       218\n",
      "\n",
      "    accuracy                           0.96      3109\n",
      "   macro avg       0.83      0.86      0.85      3109\n",
      "weighted avg       0.96      0.96      0.96      3109\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thanasis/.local/lib/python3.5/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(penalty = 'none', C=0.001, solver = 'newton-cg')\n",
    "\n",
    "# cross val\n",
    "scores = (cross_val_score(log_reg, x_train, y_train, cv=5))\n",
    "print(scores)\n",
    "\n",
    "# 2.\n",
    "log_reg.fit(x_train, y_train)\n",
    "\n",
    "# 3.\n",
    "lr_pred = log_reg.predict(x_test)\n",
    "print(accuracy_score(y_test, lr_pred))\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JLlUF0k53Wxt"
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1737,
     "status": "ok",
     "timestamp": 1591269892019,
     "user": {
      "displayName": "Ioanna Kountouri",
      "photoUrl": "",
      "userId": "18315338504972529308"
     },
     "user_tz": -180
    },
    "id": "U4gUzqfHQukh",
    "outputId": "6ef31638-f15b-4a75-fcc7-c9226d5633f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    }
   ],
   "source": [
    "# Grid search for Decision Trees\n",
    "\n",
    "grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': [None, 100, 50, 20, 10, 5]\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "gs = GridSearchCV(dt, grid, cv=2, scoring='accuracy', verbose=1) # scoring accuracy\n",
    "\n",
    "gs.fit(x_train, y_train)\n",
    "\n",
    "print(gs.best_params_) # these are the best parameters for my trainning set\n",
    "\n",
    "dt_best = gs.best_estimator_ # getting the best estimator\n",
    "\n",
    "dt_best_preds = dt_best.predict(x_test) # prediction from the best estimator\n",
    "\n",
    "print(accuracy_score(y_test, dt_best_preds)) # calculating accuracy score\n",
    "print(classification_report(y_test, dt_best_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JlNWV_La3Wxv"
   },
   "source": [
    "# K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1591269896312,
     "user": {
      "displayName": "Ioanna Kountouri",
      "photoUrl": "",
      "userId": "18315338504972529308"
     },
     "user_tz": -180
    },
    "id": "Bdaglbm13Wxw",
    "outputId": "61fec252-b37d-4a06-9ad7-cc0a176c72fb"
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'n_neighbors': [3, 5],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier(weights= 'distance', algorithm= 'auto', n_neighbors= 3)\n",
    "\n",
    "# gs = GridSearchCV(knn, grid, cv=5, scoring='f1', verbose=1) # scoring accuracy\n",
    "\n",
    "knn.fit(x_train, y_train)\n",
    "\n",
    "# print(gs.best_params_) # these are the best parameters for my trainning set\n",
    "\n",
    "#dt_best = gs.best_estimator_ # getting the best estimator\n",
    "\n",
    "dt_best_preds = knn.predict(x_test) # dt_best.predict(x_test) # prediction from the best estimator\n",
    "\n",
    "print(accuracy_score(y_test, dt_best_preds)) # calculating accuracy score\n",
    "print(classification_report(y_test, dt_best_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mItX9nJV3Wxy"
   },
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7804,
     "status": "ok",
     "timestamp": 1591269910567,
     "user": {
      "displayName": "Ioanna Kountouri",
      "photoUrl": "",
      "userId": "18315338504972529308"
     },
     "user_tz": -180
    },
    "id": "IQ5hRg9N3Wxz",
    "outputId": "e656f06b-712b-45d2-b31a-1d4eca91e998"
   },
   "outputs": [],
   "source": [
    "# Grid search for SVM\n",
    "\n",
    "grid = {\n",
    "    'kernel': ['linear', 'rbf', 'sigmoid'], # \n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "\n",
    "svm = SVC(gamma= 'scale', kernel= 'rbf', class_weight= None) # \n",
    "\n",
    "gs = GridSearchCV(svm, grid, cv=5, scoring='f1', verbose=1) # scoring accuracy\n",
    "\n",
    "svm.fit(x_train, y_train)\n",
    "#print(svm.coef_)\n",
    "#print(features)\n",
    "\n",
    "# print(gs.best_params_) # these are the best parameters for my trainning set\n",
    "\n",
    "# dt_best = gs.best_estimator_ # getting the best estimator\n",
    "\n",
    "dt_best_preds = svm.predict(x_test) # prediction from the best estimator\n",
    "\n",
    "print(accuracy_score(y_test, dt_best_preds)) # calculating accuracy score\n",
    "print(classification_report(y_test, dt_best_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mIA23QL8A9N"
   },
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 36322,
     "status": "ok",
     "timestamp": 1591269955032,
     "user": {
      "displayName": "Ioanna Kountouri",
      "photoUrl": "",
      "userId": "18315338504972529308"
     },
     "user_tz": -180
    },
    "id": "8e1CgPaR8EAn",
    "outputId": "067aadd5-7dfe-4695-c376-8dafdb8424eb"
   },
   "outputs": [],
   "source": [
    "def rforest():\n",
    "\n",
    "    var = VarianceThreshold()\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=50, n_jobs=-1)\n",
    "    rf.fit(x_train, y_train)\n",
    "    rf.feature_importances_\n",
    "\n",
    "    for c, imp in sorted(zip(features, rf.feature_importances_), key=lambda pair: pair[1], reverse=True):\n",
    "      print('{:20}: {}'.format(c, imp))\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators = 100, criterion = 'entropy')\n",
    "\n",
    "#     pipe1 = Pipeline([('scaler', S_scaler),\n",
    "#                       ('selector', var),\n",
    "#                       ('model', rf)])\n",
    "\n",
    "#     grid1 = {'selector__threshold': [0, 0.2, 0.4],\n",
    "#              'model__n_estimators': [20, 50, 100]}\n",
    "    \n",
    "    \n",
    "    # threshhold = 0.2, estimator = 100\n",
    "    # clf = GridSearchCV(pipe1, grid1)\n",
    "    rf.fit(x_train, y_train)\n",
    "\n",
    "    # print(rf.best_params_, '\\n')\n",
    "    \n",
    "    print(classification_report(y_test, rf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling random forest\n",
    "rforest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2xJvsP__vXc"
   },
   "source": [
    "# MLP - Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1785247,
     "status": "ok",
     "timestamp": 1591271749626,
     "user": {
      "displayName": "Ioanna Kountouri",
      "photoUrl": "",
      "userId": "18315338504972529308"
     },
     "user_tz": -180
    },
    "id": "qJajkCgN_ym5",
    "outputId": "8964eae7-ad80-479a-bda9-4c48b3a6310b"
   },
   "outputs": [],
   "source": [
    "def NN():\n",
    "    grid={'activation':['logistic'], # ,'tanh', 'relu'],\n",
    "          'learning_rate_init':[0.0001], # 0.001, 0.01, 0.1],\n",
    "          'momentum':[0.5] # ,0.2,0.3,0.7,0.9]\n",
    "         }\n",
    "\n",
    "    mlp=MLPClassifier() # activation = 'logistic', momentum = 0.5, learning_rate_init = 0.0001\n",
    "    gs=GridSearchCV(mlp,grid,cv=3,scoring='accuracy')\n",
    "\n",
    "    gs_result = gs.fit(x_train,y_train)\n",
    "    print(\"Best: %f using %s\" % (gs_result.best_score_, gs_result.best_params_))\n",
    "    \n",
    "    # activation = relu, learning rate = 0.01, momentum = 0.9\n",
    "    # Best: 0.937278 using {'activation': 'logistic', 'momentum': 0.5, 'learning_rate_init': 0.0001}\n",
    "    mlp_pred = gs.predict(x_test)\n",
    "    \n",
    "    print(accuracy_score(y_test,mlp_pred))\n",
    "    print(classification_report(y_test,mlp_pred))\n",
    "    return mlp_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0JjVxWq_3dd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calling neural networks\n",
    "mlp_pred = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'user_id': test1['user_id'], 'plan': mlp_pred})\n",
    "results.plan.value_counts()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MachineLearning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
